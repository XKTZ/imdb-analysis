{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "oTkN8LU2BkPI"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext.vocab\n",
    "from torch import nn\n",
    "import torchtext\n",
    "import  numpy as np\n",
    "import torchdata\n",
    "from torchtext.vocab import vocab\n",
    "from torchtext import transforms as T\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    @staticmethod\n",
    "    def _attention(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor,\n",
    "                   d_k: int = None,\n",
    "                   mask: torch.tensor = None, dropout: float = None):\n",
    "        if d_k is None:\n",
    "            d_k = k.shape[-1]\n",
    "        # transpose k's last two dimensions\n",
    "        k = torch.transpose(k, -1, -2)\n",
    "        attn = torch.matmul(q / math.sqrt(d_k), k)\n",
    "\n",
    "        if mask is not None:\n",
    "            attn = torch.masked_fill(attn, mask, 1e-9)\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "\n",
    "        if dropout is not None:\n",
    "            attn = F.dropout(attn, dropout)\n",
    "\n",
    "        out = torch.matmul(attn, v)\n",
    "\n",
    "        return out, attn\n",
    "\n",
    "    linear_q: nn.Linear\n",
    "    linear_k: nn.Linear\n",
    "    linear_v: nn.Linear\n",
    "    fc: nn.Linear\n",
    "    dropout: float\n",
    "    dropper: nn.Module\n",
    "    norm: nn.LayerNorm\n",
    "\n",
    "    head: int\n",
    "    d_k: int\n",
    "    d_v: int\n",
    "\n",
    "    def __init__(self, d_emb: int, head: int, d_k: int,\n",
    "                 d_v: int = None,\n",
    "                 dropout: float = 0.1,\n",
    "                 bias_qkv: bool = False):\n",
    "        super().__init__()\n",
    "        if d_v is None:\n",
    "            d_v = d_k\n",
    "        self.linear_q = nn.Linear(d_emb, head * d_k, bias=bias_qkv)\n",
    "        self.linear_k = nn.Linear(d_emb, head * d_k, bias=bias_qkv)\n",
    "        self.linear_v = nn.Linear(d_emb, head * d_v, bias=bias_qkv)\n",
    "        self.fc = nn.Linear(head * d_v, d_emb, bias=bias_qkv)\n",
    "        self.dropout = dropout\n",
    "\n",
    "        if dropout is not None:\n",
    "            self.dropper = nn.Dropout(dropout)\n",
    "        else:\n",
    "            self.dropper = nn.Identity()\n",
    "\n",
    "        self.norm = nn.LayerNorm(d_emb, eps=1e-6)\n",
    "\n",
    "        self.head = head\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "\n",
    "    def forward(self, q: torch.Tensor, k: torch.Tensor = None, v: torch.Tensor = None,\n",
    "                mask=None) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Forward for transformer\n",
    "        :param q: query, tensor(N, *, d_emb)\n",
    "        :param k: key (default q), tensor(N, *, d_emb)\n",
    "        :param v: value (default v), tensor(N, *, d_emb)\n",
    "        :param mask: mask, tensor(sequence)\n",
    "        :return: weight, attention\n",
    "        \"\"\"\n",
    "        resid = q\n",
    "        if k is None:\n",
    "            k = q\n",
    "        if v is None:\n",
    "            v = q\n",
    "        if mask is not None:\n",
    "            mask = torch.unsqueeze(mask, -3)  # mask on the expected head dim\n",
    "\n",
    "        q, k, v = self.linear_q(q), self.linear_k(k), self.linear_v(v)  # (N, S, H * S)\n",
    "        q = torch.transpose(q.view(*q.shape[:-1], self.head, self.d_k), -2, -3)  # (N, H, S, S)\n",
    "        k = torch.transpose(k.view(*k.shape[:-1], self.head, self.d_k), -2, -3)  # (N, H, S, S)\n",
    "        v = torch.transpose(v.view(*v.shape[:-1], self.head, self.d_v), -2, -3)  # (N, H, S, S)\n",
    "\n",
    "        weight, attn = self._attention(q, k, v, d_k=self.d_k, mask=mask, dropout=self.dropout)\n",
    "        weight = weight.transpose(-2, -3)\n",
    "        weight = weight.contiguous().view(*weight.shape[:-2], -1)\n",
    "        weight = self.dropper(self.fc(weight))\n",
    "\n",
    "        weight += resid\n",
    "\n",
    "        weight = self.norm(weight)\n",
    "\n",
    "        return weight, attn\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    dropout: float\n",
    "    w: nn.Module\n",
    "    norm: nn.Module\n",
    "\n",
    "    def __init__(self, dim: int, hidden_dim: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.w = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(dim, eps=1e-6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        resid = x\n",
    "        x = self.w(x)\n",
    "        x += resid\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerEncodingLayer(nn.Module):\n",
    "    attention: nn.Module\n",
    "    feed_forward: nn.Module\n",
    "\n",
    "    def __init__(self, d_emb: int,\n",
    "                 head: int = 1,\n",
    "                 d_k: int = 1024, d_v: int = 1024,\n",
    "                 attention_dropout: float = 0.1,\n",
    "                 forward_hidden: int = 1024,\n",
    "                 forward_dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadSelfAttention(d_emb, head, d_k, d_v, dropout=attention_dropout)\n",
    "        self.feed_forward = FeedForward(d_emb, forward_hidden, forward_dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:\n",
    "        x, _ = self.attention(x, mask=mask)\n",
    "        x = self.feed_forward(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    layer: int\n",
    "    layers: nn.ModuleList\n",
    "    norm: nn.Module\n",
    "\n",
    "    def __init__(self, layer: int, d_emb: int,\n",
    "                 head: int = 1, d_k=1024, d_v=1024,\n",
    "                 attention_dropout: float = 0.1,\n",
    "                 forward_hidden: int = 1024, forward_dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [TransformerEncodingLayer(d_emb, head, d_k, d_v, attention_dropout, forward_hidden, forward_dropout)\n",
    "             for _ in range(layer)]\n",
    "        )\n",
    "        self.layer = layer\n",
    "        self.norm = nn.LayerNorm(d_emb, eps=1e-6)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mask: torch.Tensor):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask=mask)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerDecodingLayer(nn.Module):\n",
    "    attention: nn.Module\n",
    "    encoder_decoder_attention: nn.Module\n",
    "    feed_forward: nn.Module\n",
    "\n",
    "    def __init__(self, d_emb: int,\n",
    "                 head: int = 1,\n",
    "                 d_k: int = 1024, d_v: int = 1024,\n",
    "                 attention_dropout: float = 0.1,\n",
    "                 forward_hidden: int = 1024,\n",
    "                 forward_dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadSelfAttention(d_emb, head, d_k, d_v, dropout=attention_dropout)\n",
    "        self.encoder_decoder_attention = MultiHeadSelfAttention(d_emb, head, d_k, d_v, dropout=attention_dropout)\n",
    "        self.feed_forward = FeedForward(d_emb, forward_hidden, forward_dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor,\n",
    "                encoder_kv: torch.Tensor,\n",
    "                mask_encoder: torch.Tensor,\n",
    "                mask_decoder: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        :param x: [N, seq, dim]\n",
    "        :param encoder_kv: [N, seq, dim]\n",
    "        :param mask_encoder: [N, seq, seq]\n",
    "        :param mask_decoder: [N, seq, seq]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x, _ = self.attention(x, mask=mask_decoder)\n",
    "        # Decoder in transformer depends on encoder's output\n",
    "        x, _ = self.attention(x, encoder_kv, encoder_kv, mask=mask_encoder)\n",
    "        x = self.feed_forward(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerDecoder(nn.Module):\n",
    "    layer: int\n",
    "    layers: nn.ModuleList\n",
    "    norm: nn.Module\n",
    "\n",
    "    def __init__(self, layer: int, d_emb: int,\n",
    "                 head: int = 1, d_k=1024, d_v=1024,\n",
    "                 attention_dropout: float = 0.1,\n",
    "                 forward_hidden: int = 1024, forward_dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerDecodingLayer(d_emb, head, d_k, d_v, attention_dropout, forward_hidden, forward_dropout)\n",
    "                for _ in range(layer)\n",
    "            ]\n",
    "        )\n",
    "        self.layer = layer\n",
    "        self.norm = nn.LayerNorm(d_emb, eps=1e-6)\n",
    "\n",
    "    def forward(self, x: torch.Tensor,\n",
    "                encoder_output: torch.Tensor,\n",
    "                mask_encoder: torch.Tensor,\n",
    "                mask_decoder: torch.Tensor):\n",
    "        \"\"\"\n",
    "        :param x: [N, seq, dim]\n",
    "        :param encoder_output: [N, seq, dim]\n",
    "        :param mask_encoder: [N, seq, seq]\n",
    "        :param mask_decoder: [N, seq, seq]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, encoder_output, mask_encoder, mask_decoder)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    pos: torch.Tensor\n",
    "\n",
    "    def __init__(self, dim: int, seq: int, device: torch.device = torch.device(\"cpu:0\")):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(seq, dim)\n",
    "        position = np.array([\n",
    "            [0 if i == 0 else (pos / (10000 ** (2 * i / dim))) for i in range(dim)]\n",
    "            for pos in range(seq)\n",
    "        ], dtype=float)\n",
    "        position[1:, 0::2] = np.sin(position[1:, 0::2])\n",
    "        position[1:, 1::2] = np.cos(position[1:, 1::2])\n",
    "        self.pos = torch.from_numpy(position).float().to(device)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return x + self.pos\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "\n",
    "    @staticmethod\n",
    "    def get_attention_pad_mask(seq: torch.Tensor, seq_length: int, empty: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Get sequence mask\n",
    "        :param seq: [N, seq_length]\n",
    "        :param seq_length: seq_length\n",
    "        :param empty: empty token\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        msk = torch.eq(seq, empty).byte().unsqueeze(1)\n",
    "        return msk.expand(seq.shape[0], seq_length, seq_length)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_attention_sequence_mask(batch_size: int, seq_length: int, dev: torch.device = torch.device(\"cpu:0\")):\n",
    "        shape = (batch_size, seq_length, seq_length)\n",
    "        subsequence_mask = torch.from_numpy(np.triu(np.ones(shape, dtype=int), k=1)).byte().to(dev)\n",
    "        return subsequence_mask\n",
    "\n",
    "    encoder: TransformerEncoder\n",
    "    decoder: TransformerDecoder\n",
    "\n",
    "    emb_encode: nn.Embedding\n",
    "    emb_decode: nn.Embedding\n",
    "\n",
    "    position_encode: PositionalEncoding\n",
    "    position_decode: PositionalEncoding\n",
    "\n",
    "    projection: nn.Module\n",
    "\n",
    "    seq: int\n",
    "\n",
    "    empty: int\n",
    "\n",
    "    device: torch.device\n",
    "\n",
    "    def __init__(self,\n",
    "                 dict_size_encode: int, dict_size_decode: int,\n",
    "                 d_emb: int, seq: int,\n",
    "                 layer: int = 6,\n",
    "                 head: int = 1, d_k: int = 1024, d_v: int = 1024,\n",
    "                 attention_dropout: float = 0.1,\n",
    "                 forward_hidden: int = 2048,\n",
    "                 forward_dropout: float = 0.1,\n",
    "                 emb_encode: torch.Tensor = None,\n",
    "                 emb_decode: torch.Tensor = None,\n",
    "                 empty: int = 0,\n",
    "                 device: torch.device = torch.device(\"cpu:0\")\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.seq = seq\n",
    "\n",
    "        self.encoder = TransformerEncoder(layer, d_emb, head, d_k, d_v, attention_dropout, forward_hidden,\n",
    "                                          forward_dropout)\n",
    "        self.decoder = TransformerDecoder(layer, d_emb, head, d_k, d_v, attention_dropout, forward_hidden,\n",
    "                                          forward_dropout)\n",
    "\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(d_emb, dict_size_decode, bias=False)\n",
    "        )\n",
    "\n",
    "        self.position_encode = PositionalEncoding(d_emb, seq, device=device)\n",
    "        self.position_decode = PositionalEncoding(d_emb, seq, device=device)\n",
    "\n",
    "        self.emb_encode = nn.Embedding(dict_size_encode, d_emb) if emb_encode is None \\\n",
    "            else nn.Embedding.from_pretrained(emb_encode, freeze=True)\n",
    "\n",
    "        self.emb_decode = nn.Embedding(dict_size_decode, d_emb) if emb_decode is None \\\n",
    "            else nn.Embedding.from_pretrained(emb_decode, freeze=True)\n",
    "\n",
    "        self.empty = empty\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "    def encode(self, encoder_input: torch.Tensor) -> torch.Tensor:\n",
    "        mask = self.get_attention_pad_mask(encoder_input, self.seq, self.empty) == 1\n",
    "        return self.encoder(self.position_encode(self.emb_encode(encoder_input)), mask)\n",
    "\n",
    "    def decode(self, decoder_input: torch.Tensor, encoder_input: torch.Tensor, encoder_output: torch.Tensor):\n",
    "        dec_mask = torch.gt(\n",
    "            self.get_attention_sequence_mask(decoder_input.shape[0], self.seq, self.device)\n",
    "            + self.get_attention_pad_mask(decoder_input, self.seq, self.empty),\n",
    "            0\n",
    "        )\n",
    "        enc_mask = self.get_attention_pad_mask(encoder_input, self.seq, self.empty) == 1\n",
    "        decoded = self.decoder(\n",
    "            self.position_decode(self.emb_decode(decoder_input)),\n",
    "            encoder_output, enc_mask, dec_mask\n",
    "        )\n",
    "        return self.projection(decoded)\n",
    "\n",
    "    def forward(self, encoder_input: torch.Tensor, decoder_input: torch.Tensor):\n",
    "        enc = self.encode(encoder_input)\n",
    "        return self.decode(decoder_input, encoder_input, enc)\n"
   ],
   "metadata": {
    "id": "JQvgaDqBspF-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f4fcc0484d0>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "SEED = 1234\n",
    "torch.manual_seed(SEED)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JWvKGdjtBkPM",
    "outputId": "f84d6182-6c04-4c49-cf70-5c302c10b09b"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')"
   ],
   "metadata": {
    "id": "QN6Ptn-wBkPN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_iter, test_iter = torchtext.datasets.IMDB(root='./data')\n",
    "train_list = list(train_iter)\n",
    "test_list = list(test_iter)"
   ],
   "metadata": {
    "id": "v72_wN6-BkPO"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MOST_COMMON_SIZE = 30000\n",
    "SENTENCE_LENGTH = 300\n",
    "EMBED_SIZE = 50\n",
    "MODEL_LOADING = \"model\""
   ],
   "metadata": {
    "id": "-DFz8T7ABkPP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "\n",
    "counter = Counter()\n",
    "for (label, line) in train_list:\n",
    "    counter.update(tokenizer(line))"
   ],
   "metadata": {
    "id": "Xohoo-hCBkPP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "most_common_words = counter.most_common(MOST_COMMON_SIZE + 10)[10:]\n",
    "PAD = '<PAD>'\n",
    "UNK = '<UNK>'\n",
    "BOS = '<BOS>'\n",
    "EOS = '<EOS>'\n",
    "eng_vocab = vocab(OrderedDict(most_common_words), specials=[PAD, UNK, BOS, EOS])\n",
    "eng_vocab.set_default_index(eng_vocab[UNK])"
   ],
   "metadata": {
    "id": "JxKl-5VVBkPQ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [02:41, 5.33MB/s]                           \n",
      "100%|█████████▉| 399999/400000 [00:10<00:00, 37325.28it/s]\n"
     ]
    }
   ],
   "source": [
    "glove = torchtext.vocab.GloVe(name='6B', dim=EMBED_SIZE)"
   ],
   "metadata": {
    "id": "mmWufEsTsgVR",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1f494061-7876-4f0f-8e9c-0138994463fc"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "embedding_weight_matrix = [[0 for i in range(EMBED_SIZE)] for j in range(4)]\n",
    "embedding_weight_matrix.extend(\n",
    "    [glove.get_vecs_by_tokens(word[0]) for word in most_common_words]\n",
    ")\n",
    "embedding_weight_matrix = torch.tensor(embedding_weight_matrix)"
   ],
   "metadata": {
    "id": "6HVAAVTjBkPR"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "VOCAB_SIZE = len(eng_vocab)\n",
    "\n",
    "class IMDBDataset(torch.utils.data.Dataset):\n",
    "    size: int\n",
    "    ret: list\n",
    "    targs: list\n",
    "    device: torch.device\n",
    "\n",
    "    def __init__(self, lst: list, dev: torch.device = None):\n",
    "        super().__init__()\n",
    "        self.ret = []\n",
    "        on = 0\n",
    "        self.size = len(lst)\n",
    "        self.device = torch.device('cpu:0') if dev is None else dev\n",
    "        self.targs = []\n",
    "        print('Loading Data Set')\n",
    "        tot = len(lst)\n",
    "        cnt = 0\n",
    "        for lbl, comment in lst:\n",
    "            dt = tokenizer(comment)\n",
    "            self.ret.append(\n",
    "                [eng_vocab[BOS]] + [eng_vocab[word] for word in dt[:SENTENCE_LENGTH]] + [eng_vocab[EOS]]\n",
    "            )\n",
    "            if len(dt) < SENTENCE_LENGTH:\n",
    "                self.ret[-1].extend([eng_vocab[PAD]] * (SENTENCE_LENGTH - len(dt)))\n",
    "            self.ret[-1] = torch.tensor(self.ret[-1], dtype=torch.long).to(device=dev)\n",
    "            self.targs.append(\n",
    "                torch.tensor([1, 0] if lbl == 1 else [0, 1],\n",
    "                             dtype=torch.float)\n",
    "                .to(device=dev)\n",
    "            )\n",
    "            cnt += 1\n",
    "            print(f\"\\r{cnt} / {tot}         \", end='')\n",
    "        print()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        return self.ret[idx], self.targs[idx]"
   ],
   "metadata": {
    "id": "Ff44xROJBkPR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\")"
   ],
   "metadata": {
    "id": "Py5zPherxJ8M"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading Data Set\n",
      "25000 / 25000         \n",
      "Loading Data Set\n",
      "25000 / 25000         \n"
     ]
    }
   ],
   "source": [
    "imdb_train_set = IMDBDataset(train_list)\n",
    "imdb_test_set = IMDBDataset(test_list)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J4bv91pGBkPT",
    "outputId": "175d0c58-276c-43c1-a1f2-5e7fa319de44"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_data_loader = DataLoader(imdb_train_set, batch_size=64, shuffle=True)\n",
    "test_data_loader = DataLoader(imdb_test_set, batch_size=64, shuffle=True)"
   ],
   "metadata": {
    "id": "7OUyMYBUX6qf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "\n",
    "    emb: nn.Module\n",
    "    transformer: TransformerEncoder\n",
    "    recurrent_part: nn.Module\n",
    "    predict: nn.Module\n",
    "\n",
    "    empty: int\n",
    "\n",
    "    def __init__(self, out_dim: int,\n",
    "                 transformer_layer: int = 6,\n",
    "                 gru_layer: int = 2, gru_dim: int = 512,\n",
    "                 forward_dim: int = 1024,\n",
    "                 empty: int = 0):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding.from_pretrained(embedding_weight_matrix, freeze=True)\n",
    "        self.transformer = TransformerEncoder(\n",
    "            transformer_layer, EMBED_SIZE, forward_dropout=0.2, attention_dropout=0.2\n",
    "        )\n",
    "        self.recurrent_part = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.GRU(EMBED_SIZE, gru_dim, num_layers=gru_layer, batch_first=True)\n",
    "        )\n",
    "        self.predict = nn.Sequential(\n",
    "            nn.Linear(gru_dim, forward_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(forward_dim, out_dim),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "        self.empty = empty\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        msk = Transformer.get_attention_pad_mask(x, x.shape[1], self.empty) == 1\n",
    "        x = self.emb(x)\n",
    "        x = self.transformer(x, msk)\n",
    "        all_result, final_result = self.recurrent_part(x)\n",
    "        final_result = final_result[-1]\n",
    "        return self.predict(final_result)"
   ],
   "metadata": {
    "id": "GS_qMzztBkPS"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Classifier(out_dim=2, empty=eng_vocab[PAD]).to(device)\n",
    "if MODEL_LOADING is not None:\n",
    "    model.load_state_dict(torch.load(MODEL_LOADING))"
   ],
   "metadata": {
    "id": "q8c7UkmGBkPT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "loss = nn.BCELoss().to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-5)"
   ],
   "metadata": {
    "id": "hli2iRYo-uAR"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def test(i: int, name: str, data_set: torch.utils.data.Dataset, data_loader: torch.utils.data.DataLoader):\n",
    "    model.eval()\n",
    "    cnt = 0\n",
    "    tot = len(data_set)\n",
    "    ls = 0\n",
    "    for data, lbl in data_loader:\n",
    "        data = data.to(device)\n",
    "        lbl = lbl.to(device)\n",
    "        oup = model(data)\n",
    "        out = torch.argmax(oup, dim=1)\n",
    "        targ = torch.argmax(lbl, dim=1)\n",
    "        cnt += torch.sum(out == targ).item()\n",
    "        ls += loss(oup, lbl).item()\n",
    "    ls /= len(data_loader)\n",
    "\n",
    "    print()\n",
    "    print(name)\n",
    "    print(f'Correct: {cnt}')\n",
    "    print(f'Wrong: {tot - cnt}')\n",
    "    print(f'Total: {tot}')\n",
    "    print(f'Correctness: {round(cnt / tot, 5)}')\n",
    "    print(f'Loss: {round(ls, 5)}')\n",
    "    print(\"=\" * 40)\n",
    "    model.train()\n"
   ],
   "metadata": {
    "id": "C7aZcZ3SyKy4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1:\n",
      "Loss: 0.28398\n",
      "Epoch 2:\n",
      "Loss: 0.28529\n",
      "Epoch 3:\n",
      "Loss: 0.28434\n",
      "\n",
      "Test:\n",
      "Correct: 21228\n",
      "Wrong: 3772\n",
      "Total: 25000\n",
      "Correctness: 0.84912\n",
      "Loss: 0.37428\n",
      "========================================\n",
      "Epoch 4:\n",
      "Loss: 0.28041\n",
      "Epoch 5:\n",
      "Loss: 0.27898\n",
      "Epoch 6:\n",
      "Loss: 0.28042\n",
      "\n",
      "Test:\n",
      "Correct: 21211\n",
      "Wrong: 3789\n",
      "Total: 25000\n",
      "Correctness: 0.84844\n",
      "Loss: 0.36295\n",
      "========================================\n",
      "Epoch 7:\n",
      "Loss: 0.27835\n",
      "Epoch 8:\n",
      "Loss: 0.27488\n",
      "Epoch 9:\n",
      "Loss: 0.27316\n",
      "\n",
      "Test:\n",
      "Correct: 21465\n",
      "Wrong: 3535\n",
      "Total: 25000\n",
      "Correctness: 0.8586\n",
      "Loss: 0.34163\n",
      "========================================\n",
      "Epoch 10:\n",
      "Loss: 0.27294\n",
      "Epoch 11:\n",
      "Loss: 0.27268\n",
      "Epoch 12:\n",
      "Loss: 0.27432\n",
      "\n",
      "Test:\n",
      "Correct: 21243\n",
      "Wrong: 3757\n",
      "Total: 25000\n",
      "Correctness: 0.84972\n",
      "Loss: 0.35947\n",
      "========================================\n",
      "Epoch 13:\n",
      "Loss: 0.27005\n",
      "Epoch 14:\n",
      "Loss: 0.27088\n",
      "Epoch 15:\n",
      "Loss: 0.26949\n",
      "\n",
      "Test:\n",
      "Correct: 21530\n",
      "Wrong: 3470\n",
      "Total: 25000\n",
      "Correctness: 0.8612\n",
      "Loss: 0.33814\n",
      "========================================\n",
      "Epoch 16:\n",
      "Loss: 0.26874\n",
      "Epoch 17:\n",
      "Loss: 0.26605\n",
      "Epoch 18:\n",
      "Loss: 0.26609\n",
      "\n",
      "Test:\n",
      "Correct: 21442\n",
      "Wrong: 3558\n",
      "Total: 25000\n",
      "Correctness: 0.85768\n",
      "Loss: 0.35382\n",
      "========================================\n",
      "Epoch 19:\n",
      "Loss: 0.26486\n",
      "Epoch 20:\n",
      "Loss: 0.26124\n",
      "Epoch 21:\n",
      "Loss: 0.26345\n",
      "\n",
      "Test:\n",
      "Correct: 21582\n",
      "Wrong: 3418\n",
      "Total: 25000\n",
      "Correctness: 0.86328\n",
      "Loss: 0.33096\n",
      "========================================\n",
      "Epoch 22:\n",
      "Loss: 0.2601\n",
      "Epoch 23:\n",
      "Loss: 0.25947\n",
      "Epoch 24:\n",
      "Loss: 0.25671\n",
      "\n",
      "Test:\n",
      "Correct: 21556\n",
      "Wrong: 3444\n",
      "Total: 25000\n",
      "Correctness: 0.86224\n",
      "Loss: 0.35305\n",
      "========================================\n",
      "Epoch 25:\n",
      "Loss: 0.25662\n",
      "Epoch 26:\n",
      "Loss: 0.25627\n",
      "Epoch 27:\n",
      "Loss: 0.25501\n",
      "\n",
      "Test:\n",
      "Correct: 21251\n",
      "Wrong: 3749\n",
      "Total: 25000\n",
      "Correctness: 0.85004\n",
      "Loss: 0.36432\n",
      "========================================\n",
      "Epoch 28:\n",
      "Loss: 0.25322\n",
      "Epoch 29:\n",
      "Loss: 0.25128\n",
      "Epoch 30:\n",
      "Loss: 0.25135\n",
      "\n",
      "Test:\n",
      "Correct: 20724\n",
      "Wrong: 4276\n",
      "Total: 25000\n",
      "Correctness: 0.82896\n",
      "Loss: 0.40682\n",
      "========================================\n",
      "Epoch 31:\n",
      "Loss: 0.25054\n",
      "Epoch 32:\n",
      "Loss: 0.24915\n",
      "Epoch 33:\n",
      "Loss: 0.24709\n",
      "\n",
      "Test:\n",
      "Correct: 21514\n",
      "Wrong: 3486\n",
      "Total: 25000\n",
      "Correctness: 0.86056\n",
      "Loss: 0.3461\n",
      "========================================\n",
      "Epoch 34:\n",
      "Loss: 0.24706\n",
      "Epoch 35:\n",
      "Loss: 0.24495\n",
      "Epoch 36:\n",
      "Loss: 0.24424\n",
      "\n",
      "Test:\n",
      "Correct: 21490\n",
      "Wrong: 3510\n",
      "Total: 25000\n",
      "Correctness: 0.8596\n",
      "Loss: 0.33641\n",
      "========================================\n",
      "Epoch 37:\n",
      "Loss: 0.24242\n",
      "Epoch 38:\n",
      "Loss: 0.24409\n",
      "Epoch 39:\n",
      "Loss: 0.24192\n",
      "\n",
      "Test:\n",
      "Correct: 21335\n",
      "Wrong: 3665\n",
      "Total: 25000\n",
      "Correctness: 0.8534\n",
      "Loss: 0.36373\n",
      "========================================\n",
      "Epoch 40:\n",
      "Loss: 0.24174\n",
      "Epoch 41:\n",
      "Loss: 0.23836\n",
      "Epoch 42:\n",
      "Loss: 0.23865\n",
      "\n",
      "Test:\n",
      "Correct: 21445\n",
      "Wrong: 3555\n",
      "Total: 25000\n",
      "Correctness: 0.8578\n",
      "Loss: 0.3665\n",
      "========================================\n",
      "Epoch 43:\n",
      "Loss: 0.23683\n",
      "Epoch 44:\n",
      "Loss: 0.23626\n",
      "Epoch 45:\n",
      "Loss: 0.23417\n",
      "\n",
      "Test:\n",
      "Correct: 21320\n",
      "Wrong: 3680\n",
      "Total: 25000\n",
      "Correctness: 0.8528\n",
      "Loss: 0.3781\n",
      "========================================\n",
      "Epoch 46:\n",
      "Loss: 0.23175\n",
      "Epoch 47:\n",
      "Loss: 0.23283\n",
      "Epoch 48:\n",
      " 213 / 391 : Loss: 0.44028                       "
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-19-5bb6eba5a42e>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     12\u001B[0m         \u001B[0mls\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlbl\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m         \u001B[0mls\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m         \u001B[0moptim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m         \u001B[0mls_avg\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mls\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m         \u001B[0mcnt\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    138\u001B[0m                 \u001B[0mprofile_name\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"Optimizer.step#{}.step\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    139\u001B[0m                 \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprofiler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecord_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprofile_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 140\u001B[0;31m                     \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    141\u001B[0m                     \u001B[0mobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_optimizer_step_code\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    142\u001B[0m                     \u001B[0;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\u001B[0m in \u001B[0;36m_use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     21\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m             \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_grad_enabled\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdefaults\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'differentiable'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 23\u001B[0;31m             \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     24\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m             \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_grad_enabled\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprev_grad\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self, closure, grad_scaler)\u001B[0m\n\u001B[1;32m    232\u001B[0m                     \u001B[0mstate_steps\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'step'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    233\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 234\u001B[0;31m             adam(params_with_grad,\n\u001B[0m\u001B[1;32m    235\u001B[0m                  \u001B[0mgrads\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    236\u001B[0m                  \u001B[0mexp_avgs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001B[0m in \u001B[0;36madam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[1;32m    298\u001B[0m         \u001B[0mfunc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_single_tensor_adam\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    299\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 300\u001B[0;31m     func(params,\n\u001B[0m\u001B[1;32m    301\u001B[0m          \u001B[0mgrads\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    302\u001B[0m          \u001B[0mexp_avgs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001B[0m in \u001B[0;36m_single_tensor_adam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[1;32m    408\u001B[0m                 \u001B[0mdenom\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mmax_exp_avg_sqs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msqrt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0mbias_correction2_sqrt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0meps\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    409\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 410\u001B[0;31m                 \u001B[0mdenom\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mexp_avg_sq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msqrt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0mbias_correction2_sqrt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0meps\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    411\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    412\u001B[0m             \u001B[0mparam\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maddcdiv_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexp_avg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdenom\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0mstep_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "EPOCH = 400\n",
    "for epoch in range(1, EPOCH + 1):\n",
    "    print(f\"Epoch {epoch}:\")\n",
    "    ls_avg = 0\n",
    "    cnt = 0\n",
    "    tot = len(train_data_loader)\n",
    "    for data, lbl in train_data_loader:\n",
    "        optim.zero_grad()\n",
    "        data = data.to(device)\n",
    "        lbl = lbl.to(device)\n",
    "        y = model(data)\n",
    "        ls = loss(y, lbl)\n",
    "        ls.backward()\n",
    "        optim.step()\n",
    "        ls_avg += ls.item()\n",
    "        cnt += 1\n",
    "        print(f\"\\r{cnt} / {tot} : Loss: {round(ls.item(), 5)}                       \", end=\"\")\n",
    "    print(f\"\\rLoss: {round(ls_avg / len(train_data_loader), 5)}\")\n",
    "    torch.save(model.state_dict(), f\"models/model_{epoch}\")\n",
    "    if epoch % 3 == 0:\n",
    "      test(epoch, \"Test:\", imdb_test_set, test_data_loader)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FnADYxgxBkPU",
    "outputId": "273b851b-cd58-4db9-d21f-87aff431f36e",
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
